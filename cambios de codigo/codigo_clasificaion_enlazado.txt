from tkinter import *
from PIL import Image, ImageTk
import imutils
import cv2
import numpy as np
from ultralytics import YOLO
import math
import control_contenedores  # Asegúrate de tener este archivo correctamente configurado
import time# Definición de variables globales
arduino = None  # Esto se inicializa en ventana_principal

def clean_lbl():
    # Limpiar etiquetas de imagen
    lblimg.config(image='')
    lblimgtxt.config(image='')

def images(img, imgtxt):
    # Mostrar imágenes en la GUI
    img = np.array(img, dtype="uint8")
    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    img = Image.fromarray(img)
    img_ = ImageTk.PhotoImage(image=img)
    lblimg.configure(image=img_)
    lblimg.image = img_

    imgtxt = np.array(imgtxt, dtype="uint8")
    imgtxt = cv2.cvtColor(imgtxt, cv2.COLOR_BGR2RGB)
    imgtxt = Image.fromarray(imgtxt)
    img_txt = ImageTk.PhotoImage(image=imgtxt)
    lblimgtxt.configure(image=img_txt)
    lblimgtxt.image = img_txt

    # Liberar recursos de PIL
    img.close()
    imgtxt.close()

# Scanning Function
def Scanning():
    global img_organico, img_papel, img_plastico, img_no_residuo
    global img_organicotxt, img_papeltxt, img_plasticotxt, img_no_residuotxt, pantalla
    global lblimg, lblimgtxt,detect
    global last_detection_time
    detect = False
    # Interfaz
    lblimg = Label(pantalla)
    lblimg.place(x=63, y=135)

    lblimgtxt = Label(pantalla)
    lblimgtxt.place(x=1040, y=477)
    detect = False

    # Read VideoCapture
    if cap is not None:
        ret, frame = cap.read()
        frame_show = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        # True
        if ret:
            # Detección con YOLO
            results = model(frame, stream=True, verbose=False)
            for res in results:
                boxes = res.boxes
                for box in boxes:
                    #detect = True
                    # Coordenadas de la caja delimitadora
                     x1, y1, x2, y2 = box.xyxy[0]
                     x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)

                    # Asegurarse de que las coordenadas no sean negativas
                     x1, y1, x2, y2 = max(0, x1), max(0, y1), max(0, x2), max(0, y2)

                    # Clase del residuo detectado
                     cls = int(box.cls[0])

                    # Confianza
                     conf = math.ceil(box.conf[0])

                     current_time = time.time()
                     if current_time - last_detection_time > 5:  # Pausa de 3 segundos entre detecciones
                        detect = False

                     if not detect:
                        # Clasificar y enviar señales al Arduino según la clase del residuo
                        if cls in [0, 1, 5]:  # Orgánico (Frutas, Verduras, Alimentos)
                            cv2.rectangle(frame_show, (x1, y1), (x2, y2), (0, 255, 0), 2)
                            text = f'{clsName[cls]} {int(conf) * 100}%'
                            cv2.putText(frame_show, text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                            images(img_organico, img_organicotxt)
                            control_contenedores.enviar_comando_a_arduino(cls)  # Enviar comando para orgánico
                            print(f"Comando enviado para orgánico {cls}")
                        elif cls in [6, 7, 8]:  # Papel (Envoltorios, Barbijos, Papel higiénico)
                            cv2.rectangle(frame_show, (x1, y1), (x2, y2), (255, 255, 0), 2)
                            text = f'{clsName[cls]} {int(conf) * 100}%'
                            cv2.putText(frame_show, text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)
                            images(img_papel, img_papeltxt)
                            control_contenedores.enviar_comando_a_arduino(cls)  # Enviar comando para papel
                            print(f"Comando enviado para papel {cls}")
                        elif cls in [2, 3, 4]:  # Plástico (Botellas, Vasos)
                            cv2.rectangle(frame_show, (x1, y1), (x2, y2), (0, 0, 255), 2)
                            text = f'{clsName[cls]} {int(conf) * 100}%'
                            cv2.putText(frame_show, text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                            images(img_plastico, img_plasticotxt)
                            control_contenedores.enviar_comando_a_arduino(cls)  # Enviar comando para plástico
                            print(f"Comando enviado para plástico {cls}")

                        detect = True
                        last_detection_time = time.time()  # Actualizar el tiempo de la última detección
                        # Si no se detecta ningún objeto
                    #if not detect:
                       # clean_lbl()

            # Redimensionar el frame
            frame_show = imutils.resize(frame_show, width=640)

            # Convertir el video para mostrarlo en la GUI
            im = Image.fromarray(frame_show)
            img = ImageTk.PhotoImage(image=im)
            lblVideo.configure(image=img)
            lblVideo.image = img
            lblVideo.after(10, Scanning)

            # Liberar recursos PIL
            im.close()

        else:
            cap.release()
            cv2.destroyAllWindows()  # Cerrar todas las ventanas de OpenCV

# Función para manejar el cierre de la ventana
def on_closing():
    global cap
    if cap is not None:
        cap.release()  # Liberar la cámara
    pantalla.destroy()  # Cerrar la ventana de la interfaz
    print("Interfaz cerrada. Deteniendo el sistema.")
# main
def ventana_principal():
    global cap, lblVideo, model, clsName, img_organico, img_papel, img_plastico, img_no_residuo
    global img_organicotxt, img_papeltxt, img_plasticotxt,img_no_residuotxt, pantalla
    global last_detection_time  #
    # Inicializar la conexión con Arduino
    arduino = control_contenedores.inicializar_conexion_arduino()

    # Ventana principal
    pantalla = Tk()
    pantalla.title("RECICLAJE INTELIGENTE")
    pantalla.geometry("1280x720")

    # Fondo
    imagenF = PhotoImage(file="setUp/Canva1.png")
    background = Label(image=imagenF, text="Inicio")
    background.place(x=0, y=0, relwidth=1, relheight=1)

    # Inicializar la variable de tiempo para las detecciones
    last_detection_time = time.time()
    # Nombres de las clases (Ajustado para que coincidan con 'data.yaml')
    clsName = [
        'ORGANICO',  # Clase 0
        'ORGANICO',  # Clase 1
        'PLASTICO',  # Clase 2
        'PLASTICO',  # Clase 3
        'PLASTICO',  # Clase 4
        'ORGANICO',  # Clase 5
        'PAPEL',  # Clase 6
        'PAPEL',  # Clase 7
        'PAPEL'   # Clase 8
    ]

    # Modelo de YOLO
    model = YOLO('Modelos/best.pt')

    # Imágenes
    img_organico = cv2.imread("setUp/organico.png")
    img_papel = cv2.imread("setUp/papel.png")
    img_plastico = cv2.imread("setUp/plastico.png")
    img_no_residuo = cv2.imread("setUp/no_residuo.png")

    img_organicotxt = cv2.imread("setUp/organicotxt.png")
    img_papeltxt = cv2.imread("setUp/papeltxt.png")
    img_plasticotxt = cv2.imread("setUp/plasticotxt.png")
    img_no_residuotxt = cv2.imread("setUp/no_residuotxt.png")

    # Video
    lblVideo = Label(pantalla)
    lblVideo.place(x=338, y=133)

    # Elegimos la cámara
    cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)
    cap.set(3, 1280)
    cap.set(4, 720)
    Scanning()

    # Configurar la función de cierre
    pantalla.protocol("WM_DELETE_WINDOW", on_closing)

    # Mantener la ventana abierta
    pantalla.mainloop()

VERSION NUMERO 2 AQUI YA DETECTA LOS RESIDUOS LOS SERVOMOTORES ENVIANDO UN SOLO COMANDO Y  SE MUEVE EL SERVO

from tkinter import *
from PIL import Image, ImageTk
import imutils
import cv2
import numpy as np
from ultralytics import YOLO
import math
import control_contenedores  # Asegúrate de tener este archivo correctamente configurado
import time

# Variables globales
arduino = None
ultimo_cls = None  # Para almacenar la última clase detectada
ultimo_tiempo_deteccion = None  # Para almacenar el tiempo de la última detección
detect_count = 0  # Contador de detecciones consecutivas

# Parámetros ajustables
DETECTIONS_REQUIRED = 5  # Número de detecciones consecutivas necesarias
CONFIDENCE_THRESHOLD = 0.6  # Umbral de confianza (60%)

def Scanning():
    global ultimo_cls, ultimo_tiempo_deteccion, detect_count
    detect = False

    # Read VideoCapture
    if cap is not None:
        ret, frame = cap.read()
        frame_show = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        # True
        if ret:
            # Detección con YOLO
            results = model(frame, stream=True, verbose=False)
            for res in results:
                boxes = res.boxes
                for box in boxes:
                    # Coordenadas de la caja delimitadora
                    x1, y1, x2, y2 = box.xyxy[0]
                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)

                    # Asegurarse de que las coordenadas no sean negativas
                    x1, y1, x2, y2 = max(0, x1), max(0, y1), max(0, x2), max(0, y2)

                    # Clase del residuo detectado
                    cls = int(box.cls[0])

                    # Confianza
                    conf = box.conf[0]

                    # Si la confianza es suficiente, procesar la detección
                    if conf >= CONFIDENCE_THRESHOLD:
                        # Si la detección es de la misma clase que la anterior
                        if cls == ultimo_cls:
                            detect_count += 1
                        else:
                            detect_count = 0  # Reiniciar el contador si cambia la clase

                        # Verificar si se han cumplido las detecciones consecutivas necesarias
                        if detect_count >= DETECTIONS_REQUIRED:
                            # Enviar la señal una vez que la detección se estabilice
                            if cls in [0, 1, 5]:  # Orgánico
                                control_contenedores.enviar_comando_a_arduino(cls)
                                print(f"Comando enviado para orgánico {cls}")
                            elif cls in [6, 7, 8]:  # Papel
                                control_contenedores.enviar_comando_a_arduino(cls)
                                print(f"Comando enviado para papel {cls}")
                            elif cls in [2, 3, 4]:  # Plástico
                                control_contenedores.enviar_comando_a_arduino(cls)
                                print(f"Comando enviado para plástico {cls}")

                            # Reiniciar el contador después de enviar la señal
                            detect_count = 0

                        # Actualizar la última clase detectada y el tiempo
                        ultimo_cls = cls
                        ultimo_tiempo_deteccion = time.time()

            # Redimensionar el frame
            frame_show = imutils.resize(frame_show, width=640)

            # Convertir el video para mostrarlo en la GUI
            im = Image.fromarray(frame_show)
            img = ImageTk.PhotoImage(image=im)
            lblVideo.configure(image=img)
            lblVideo.image = img
            lblVideo.after(10, Scanning)

            # Liberar recursos PIL
            im.close()

        else:
            cap.release()
            cv2.destroyAllWindows()  # Cerrar todas las ventanas de OpenCV

# Función para manejar el cierre de la ventana
def on_closing():
    global cap
    if cap is not None:
        cap.release()  # Liberar la cámara
    pantalla.destroy()  # Cerrar la ventana de la interfaz
    print("Interfaz cerrada. Deteniendo el sistema.")

# main
def ventana_principal():
    global cap, lblVideo, model, clsName, img_organico, img_papel, img_plastico, img_no_residuo
    global img_organicotxt, img_papeltxt, img_plasticotxt,img_no_residuotxt, pantalla
    global ultimo_tiempo_deteccion

    # Inicializar la conexión con Arduino
    arduino = control_contenedores.inicializar_conexion_arduino()

    # Ventana principal
    pantalla = Tk()
    pantalla.title("RECICLAJE INTELIGENTE")
    pantalla.geometry("1280x720")

    # Fondo
    imagenF = PhotoImage(file="setUp/Canva1.png")
    background = Label(image=imagenF, text="Inicio")
    background.place(x=0, y=0, relwidth=1, relheight=1)

    # Inicializar la variable de tiempo para las detecciones
    ultimo_tiempo_deteccion = time.time()

    # Nombres de las clases (Ajustado para que coincidan con 'data.yaml')
    clsName = [
        'ORGANICO',  # Clase 0
        'ORGANICO',  # Clase 1
        'PLASTICO',  # Clase 2
        'PLASTICO',  # Clase 3
        'PLASTICO',  # Clase 4
        'ORGANICO',  # Clase 5
        'PAPEL',  # Clase 6
        'PAPEL',  # Clase 7
        'PAPEL'   # Clase 8
    ]

    # Modelo de YOLO
    model = YOLO('Modelos/best.pt')

    # Imágenes
    img_organico = cv2.imread("setUp/organico.png")
    img_papel = cv2.imread("setUp/papel.png")
    img_plastico = cv2.imread("setUp/plastico.png")
    img_no_residuo = cv2.imread("setUp/no_residuo.png")

    img_organicotxt = cv2.imread("setUp/organicotxt.png")
    img_papeltxt = cv2.imread("setUp/papeltxt.png")
    img_plasticotxt = cv2.imread("setUp/plasticotxt.png")
    img_no_residuotxt = cv2.imread("setUp/no_residuotxt.png")

    # Video
    lblVideo = Label(pantalla)
    lblVideo.place(x=338, y=133)

    # Elegimos la cámara
    cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)
    cap.set(3, 1280)
    cap.set(4, 720)
    Scanning()

    # Configurar la función de cierre
    pantalla.protocol("WM_DELETE_WINDOW", on_closing)

    # Mantener la ventana abierta
    pantalla.mainloop()


version n3 donde se detecta y Tambien muestra los boxes y rectangulos


from tkinter import *
from PIL import Image, ImageTk
import imutils
import cv2
import numpy as np
from ultralytics import YOLO
import math
import control_contenedores  # Asegúrate de tener este archivo correctamente configurado
import time

# Variables globales
arduino = None
ultimo_cls = None  # Para almacenar la última clase detectada
ultimo_tiempo_deteccion = None  # Para almacenar el tiempo de la última detección
detect_count = 0  # Contador de detecciones consecutivas

# Parámetros ajustables
DETECTIONS_REQUIRED = 5  # Número de detecciones consecutivas necesarias
CONFIDENCE_THRESHOLD = 0.6  # Umbral de confianza (60%)

def Scanning():
    global ultimo_cls, ultimo_tiempo_deteccion, detect_count
    detect = False

    # Read VideoCapture
    if cap is not None:
        ret, frame = cap.read()
        frame_show = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        # True
        if ret:
            # Detección con YOLO
            results = model(frame, stream=True, verbose=False)
            for res in results:
                boxes = res.boxes
                for box in boxes:
                    # Coordenadas de la caja delimitadora
                    x1, y1, x2, y2 = box.xyxy[0]
                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)

                    # Asegurarse de que las coordenadas no sean negativas
                    x1, y1, x2, y2 = max(0, x1), max(0, y1), max(0, x2), max(0, y2)

                    # Clase del residuo detectado
                    cls = int(box.cls[0])

                    # Confianza
                    conf = box.conf[0]

                    # Si la confianza es suficiente, procesar la detección
                    if conf >= CONFIDENCE_THRESHOLD:
                        # Dibujar el rectángulo alrededor del objeto detectado
                        color = (0, 255, 0) if cls in [0, 1, 5] else (255, 255, 0) if cls in [6, 7, 8] else (0, 0, 255)
                        cv2.rectangle(frame_show, (x1, y1), (x2, y2), color, 2)

                        # Texto con la clase y confianza
                        text = f'{clsName[cls]} {int(conf * 100)}%'
                        cv2.putText(frame_show, text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

                        # Si la detección es de la misma clase que la anterior
                        if cls == ultimo_cls:
                            detect_count += 1
                        else:
                            detect_count = 0  # Reiniciar el contador si cambia la clase

                        # Verificar si se han cumplido las detecciones consecutivas necesarias
                        if detect_count >= DETECTIONS_REQUIRED:
                            # Enviar la señal una vez que la detección se estabilice
                            if cls in [0, 1, 5]:  # Orgánico
                                control_contenedores.enviar_comando_a_arduino(cls)
                                print(f"Comando enviado para orgánico {cls}")
                            elif cls in [6, 7, 8]:  # Papel
                                control_contenedores.enviar_comando_a_arduino(cls)
                                print(f"Comando enviado para papel {cls}")
                            elif cls in [2, 3, 4]:  # Plástico
                                control_contenedores.enviar_comando_a_arduino(cls)
                                print(f"Comando enviado para plástico {cls}")

                            # Reiniciar el contador después de enviar la señal
                            detect_count = 0

                        # Actualizar la última clase detectada y el tiempo
                        ultimo_cls = cls
                        ultimo_tiempo_deteccion = time.time()

            # Redimensionar el frame
            frame_show = imutils.resize(frame_show, width=640)

            # Convertir el video para mostrarlo en la GUI
            im = Image.fromarray(frame_show)
            img = ImageTk.PhotoImage(image=im)
            lblVideo.configure(image=img)
            lblVideo.image = img
            lblVideo.after(10, Scanning)

            # Liberar recursos PIL
            im.close()

        else:
            cap.release()
            cv2.destroyAllWindows()  # Cerrar todas las ventanas de OpenCV

# Función para manejar el cierre de la ventana
def on_closing():
    global cap
    if cap is not None:
        cap.release()  # Liberar la cámara
    pantalla.destroy()  # Cerrar la ventana de la interfaz
    print("Interfaz cerrada. Deteniendo el sistema.")

# main
def ventana_principal():
    global cap, lblVideo, model, clsName, img_organico, img_papel, img_plastico, img_no_residuo
    global img_organicotxt, img_papeltxt, img_plasticotxt, img_no_residuotxt, pantalla
    global ultimo_tiempo_deteccion

    # Inicializar la conexión con Arduino
    arduino = control_contenedores.inicializar_conexion_arduino()

    # Ventana principal
    pantalla = Tk()
    pantalla.title("RECICLAJE INTELIGENTE")
    pantalla.geometry("1280x720")

    # Fondo
    imagenF = PhotoImage(file="setUp/Canva1.png")
    background = Label(image=imagenF, text="Inicio")
    background.place(x=0, y=0, relwidth=1, relheight=1)

    # Inicializar la variable de tiempo para las detecciones
    ultimo_tiempo_deteccion = time.time()

    # Nombres de las clases (Ajustado para que coincidan con 'data.yaml')
    clsName = [
        'ORGANICO',  # Clase 0
        'ORGANICO',  # Clase 1
        'PLASTICO',  # Clase 2
        'PLASTICO',  # Clase 3
        'PLASTICO',  # Clase 4
        'ORGANICO',  # Clase 5
        'PAPEL',  # Clase 6
        'PAPEL',  # Clase 7
        'PAPEL'   # Clase 8
    ]

    # Modelo de YOLO
    model = YOLO('Modelos/best.pt')

    # Video
    lblVideo = Label(pantalla)
    lblVideo.place(x=338, y=133)

    # Elegimos la cámara
    cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)
    cap.set(3, 1280)
    cap.set(4, 720)
    Scanning()

    # Configurar la función de cierre
    pantalla.protocol("WM_DELETE_WINDOW", on_closing)

    # Mantener la ventana abierta
    pantalla.mainloop()


